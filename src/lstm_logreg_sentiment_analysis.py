# -*- coding: utf-8 -*-
"""lstm_logreg_sentiment_analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yU2NKmM_a7E8Tj4_6uuTAmHj_Q6zbyP0
"""

# 📥 Import Library
import tensorflow as tf
import tensorflow_datasets as tfds

# 🔥 Load Dataset IMDB Reviews
dataset, info = tfds.load("imdb_reviews", with_info=True, as_supervised=True)

# ✅ Cek jumlah data
print(f"Jumlah Data: {info.splits['train'].num_examples} training & {info.splits['test'].num_examples} testing")

# 🔍 Contoh Data (Teks + Label 0=Negatif, 1=Positif)
for text, label in dataset['train'].take(1):
    print("\n🎬 Review:", text.numpy().decode('utf-8'))
    print("🤖 Label Sentimen:", label.numpy())  # 0 = Negatif, 1 = Positif

import re
import string
import nltk
from nltk.corpus import stopwords

# 📌 Download Stopwords NLTK
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# ✂️ Fungsi Preprocessing Teks
def clean_text(text):
    text = text.numpy().decode("utf-8")  # Konversi byte ke string
    text = text.lower()  # Ubah jadi huruf kecil
    text = re.sub(f"[{string.punctuation}]", "", text)  # Hapus punctuation
    text = " ".join([word for word in text.split() if word not in stop_words])  # Hapus stopwords
    return text

# ✅ Contoh hasil preprocessing (Cek apakah bersih!)
for text, label in dataset['train'].take(1):
    cleaned_text = clean_text(text)
    print("\n🎬 Original Review:", text.numpy().decode('utf-8'))
    print("✂️ Cleaned Review:", cleaned_text)

"""## Feature Extraction menggunakan TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer

# 🔥 Buat TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)  # Ambil 5000 kata paling penting

# 📌 Contoh Dataset (Ambil 5 Review buat Testing)
sample_texts = [
    "this movie was absolutely terrible and I hated it",
    "one of the best movies I have ever seen!",
    "the story was boring but the acting was great",
    "I really enjoyed this film, it was so much fun to watch",
    "what a waste of time, I regret watching this"
]

# 🔄 Konversi Teks ke TF-IDF
tfidf_matrix = vectorizer.fit_transform(sample_texts)

# ✅ Cek Hasilnya
print("\n🔥 TF-IDF Matrix:")
print(tfidf_matrix.toarray())  # Konversi ke numpy array buat dilihat
print("\n📌 Fitur Kata:")
print(vectorizer.get_feature_names_out())  # Cek kata-kata yang dipakai

"""## Feature Extraction menggunakan Word Embeddings (Word2Vec / Glove)"""

import gensim.downloader as api

# 🔥 Load Pre-trained GloVe (200D biar ringan)
glove_model = api.load("glove-wiki-gigaword-200")

# 🔍 Cek Vektor Kata
word = "terrible"
if word in glove_model:
    print(f"\n✅ Vektor untuk kata '{word}':")
    print(glove_model[word])

# 🔥 Cek Kata yang Mirip
print("\n🔥 Kata yang mirip dengan 'terrible':")
print(glove_model.most_similar("terrible"))

"""## Training Model Sentiment Analysis

### Logistic Regression
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# 📝 Pisahin teks & label dari dataset 'train'
X = dataset['train'].map(lambda x, y: x)  # Ambil teks
y = dataset['train'].map(lambda x, y: y)  # Ambil label

# ✂️ Preprocessing → Bersihin Teks
def clean_text(text):
    text = text.lower()  # Konversi ke lowercase
    text = re.sub(f"[{string.punctuation}]", "", text)  # Hapus punctuation
    text = " ".join([word for word in text.split() if word not in stop_words])  # Hapus stopwords
    return text

# ✅ Konversi Dataset ke List
X_list = [x.numpy().decode("utf-8") for x, _ in dataset['train']]
y_list = [y.numpy() for _, y in dataset['train']]

# 📝 Konversi ke Pandas DataFrame (Biar lebih gampang diolah)
import pandas as pd
df = pd.DataFrame({'review': X_list, 'label': y_list})

# ✂️ Bersihin Teks
df['clean_review'] = df['review'].apply(clean_text)

# ✅ Final Output
X = df['clean_review']
y = df['label']

# 🔄 TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)
X_tfidf = vectorizer.fit_transform(X)

# 📌 Split Data Training & Testing
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# 🔥 Train Model Logistic Regression
model_lr = LogisticRegression()
model_lr.fit(X_train, y_train)

# ✅ Evaluasi Model
y_pred = model_lr.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"\n🎯 Akurasi Logistic Regression: {accuracy:.4f}")
print("\n📌 Classification Report:\n", classification_report(y_test, y_pred))

"""### Long-Short Term Memory"""

!pip install tensorflow-text

from tensorflow import keras
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences
from keras.layers import Embedding, LSTM, Dense

# 🔥 Hyperparameter
MAX_WORDS = 10000  # Jumlah kata yang dipakai
MAX_LEN = 200  # Panjang maksimum setiap review

# 📌 Tokenisasi + Word Embeddings
tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token="<OOV>")
tokenizer.fit_on_texts(X)

X_seq = tokenizer.texts_to_sequences(X)
X_pad = pad_sequences(X_seq, maxlen=MAX_LEN, padding="post", truncating="post")

# 📌 Split Data
X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)

# 🔥 Build Model LSTM
model_lstm = keras.Sequential([
    Embedding(input_dim=MAX_WORDS, output_dim=50, input_length=MAX_LEN),
    LSTM(64, return_sequences=True),
    LSTM(32),
    Dense(1, activation="sigmoid")  # Output 1 neuron (0 = Negatif, 1 = Positif)
])

# ✅ Compile Model
model_lstm.compile(loss="binary_crossentropy",
                   optimizer="adam",
                   metrics=["accuracy"])

# 🚀 Train Model
history = model_lstm.fit(X_train,
                         y_train,
                         validation_data=(X_test, y_test),
                         epochs=5,
                         batch_size=32)

# ✅ Evaluasi Model
_, accuracy = model_lstm.evaluate(X_test, y_test)
print(f"\n🎯 Akurasi LSTM: {accuracy:.4f}")

import numpy as np

# 🔍 Contoh Review Baru buat Prediksi
new_reviews = [
    "This movie was absolutely amazing, I loved every second of it!",  # Positif
    "What a waste of time, I regret watching this terrible film.",  # Negatif
    "The acting was decent but the story was very boring.",  # Negatif
    "One of the best movies I have ever seen!",  # Positif
]

# ✅ 1️⃣ TESTING MODEL LOGISTIC REGRESSION
def predict_logistic_regression(reviews):
    reviews_tfidf = vectorizer.transform(reviews)  # Konversi teks ke TF-IDF
    predictions = model_lr.predict(reviews_tfidf)
    return ["Positif 😃" if pred == 1 else "Negatif 😡" for pred in predictions]

# ✅ 2️⃣ TESTING MODEL LSTM
def predict_lstm(reviews):
    reviews_seq = tokenizer.texts_to_sequences(reviews)  # Konversi teks ke angka
    reviews_pad = pad_sequences(reviews_seq, maxlen=MAX_LEN, padding="post")
    predictions = model_lstm.predict(reviews_pad)
    return ["Positif 😃" if pred > 0.5 else "Negatif 😡" for pred in predictions]

# 🔥 Lakukan Prediksi
logistic_results = predict_logistic_regression(new_reviews)
lstm_results = predict_lstm(new_reviews)

# 📌 Tampilkan Hasil Prediksi
print("\n🎯 HASIL PREDIKSI SENTIMEN:")
for i, review in enumerate(new_reviews):
    print(f"\n🎬 Review: {review}")
    print(f"🤖 Logistic Regression: {logistic_results[i]}")
    print(f"🤖 LSTM: {lstm_results[i]}")